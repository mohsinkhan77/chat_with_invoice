{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvTPRErEO2cl"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "LCJL7_hQO3jW"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xjw-LFKoD1-"
      },
      "source": [
        "# Gemini API: Analyze a Video - Historic Event Recognition\n",
        "\n",
        "This notebook shows how you can use Gemini models' multimodal capabilities to recognize which historic event is happening in the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJY5C59gPf-m"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NwP4PBGWoQiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0daf91-f378-4e6a-c737-a5ee357df687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsMCUn_nRRtV"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yGjQlQ9hoSOk"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = \"AIzaSyAaVRtDjAjUd7NpCxM-2Qc696xphpfw35c\"\n",
        "client = genai.Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y6o91Xb7RZb"
      },
      "source": [
        "## Example\n",
        "\n",
        "This example uses [video of President Ronald Reagan's Speech at the Berlin Wall](https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4) taken on June 12 1987."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M794IEOG7QzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b08411e-7f9a-40e2-bf2b-564b63a501c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-03 07:01:32--  https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.112.80, 3.5.12.82, 16.15.179.40, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.112.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 628645171 (600M) [video/mp4]\n",
            "Saving to: ‘berlin.mp4’\n",
            "\n",
            "berlin.mp4          100%[===================>] 599.52M  6.29MB/s    in 2m 8s   \n",
            "\n",
            "2025-09-03 07:03:41 (4.69 MB/s) - ‘berlin.mp4’ saved [628645171/628645171]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download video\n",
        "path = \"berlin.mp4\"\n",
        "url = \"https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4\"\n",
        "!wget $url -O $path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "efnp0oAq7kYx"
      },
      "outputs": [],
      "source": [
        "# Upload video\n",
        "video_file = client.files.upload(file=path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ij9-oG3g7yyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80bc1be-40e7-4af0-a85a-521c037b716c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".............."
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Wait until the uploaded video is available\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "  print('.', end='')\n",
        "  time.sleep(5)\n",
        "  video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "  raise ValueError(video_file.state.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFG1q42HTHmp"
      },
      "source": [
        "The uploaded video is ready for processing. This prompt instructs the model to provide basic information about the historical events portrayed in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Zhnsiy9O8OXG"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "  You are historian who specializes in events caught on film.\n",
        "  When you receive a video answer following questions:\n",
        "  what is the event about in the video?\n",
        "  how many people are present in the video?\n",
        "  When did it happen?\n",
        "  Who is the most important person in video?\n",
        "  How the event is called?\n",
        "  you have to answer any question related to the video .\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "y1ltzkGLKvrb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbM5XRJjp6T"
      },
      "source": [
        "Some historic events touch on controversial topics that may get flagged by Gemini API, which blocks the response for the query.\n",
        "\n",
        "Because of this, it might be a good idea to turn off safety settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PWLK7TEi7_mP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "0c9aaf7f-df48-4673-df33-5a5019598c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/genai/_common.py:474: UserWarning: HARM_CATEGORY_VIOLENCE is not a valid HarmCategory\n",
            "  warnings.warn(f\"{value} is not a valid {cls.__name__}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* GenerateContentRequest.safety_settings[4]: element predicate failed: $.category in (HarmCategory.HARM_CATEGORY_HATE_SPEECH, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, HarmCategory.HARM_CATEGORY_HARASSMENT, HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY)\\n', 'status': 'INVALID_ARGUMENT'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2613857288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMODEL_ID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-2.5-flash\"\u001b[0m \u001b[0;31m# @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m response = client.models.generate_content(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"models/{MODEL_ID}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     contents=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   6519\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6520\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6521\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   6522\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6523\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5253\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5255\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   5256\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5257\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m     response_body = (\n\u001b[1;32m   1268\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m   async def _async_request_once(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       )\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m       return HttpResponse(\n\u001b[1;32m   1065\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* GenerateContentRequest.safety_settings[4]: element predicate failed: $.category in (HarmCategory.HARM_CATEGORY_HATE_SPEECH, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, HarmCategory.HARM_CATEGORY_HARASSMENT, HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY)\\n', 'status': 'INVALID_ARGUMENT'}}"
          ]
        }
      ],
      "source": [
        "from google.genai import types\n",
        "\n",
        "MODEL_ID=\"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}\n",
        "response = client.models.generate_content(\n",
        "    model=f\"models/{MODEL_ID}\",\n",
        "    contents=[\n",
        "        \"what is the video about\",\n",
        "        video_file\n",
        "        ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt,\n",
        "        safety_settings=safety_settings,\n",
        "        ),\n",
        "    )\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6ByVwbmTfve"
      },
      "source": [
        "As you can see, the model correctly provided information about the dates, Ronald Reagan, who was the main subject of the video, and the name of this event.\n",
        "\n",
        "You can delete the video to prevent unnecessary data storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SomiSVmu8Czk"
      },
      "outputs": [],
      "source": [
        "# Delete video\n",
        "#client.files.delete(name=video_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBM_LtQLLJA9"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Now you know how you can prompt Gemini models with videos and use them to recognize historic events.\n",
        "\n",
        "This notebook shows only one of many use cases. Check the [Video understanding](../quickstarts/Video_understanding.ipynb) notebook for more examples of using the Gemini API with videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7ce725"
      },
      "source": [
        "# Task\n",
        "Generate a Gradio application to analyze a video using the Gemini model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "199c2ff0"
      },
      "source": [
        "## Install gradio\n",
        "\n",
        "### Subtask:\n",
        "Install the Gradio library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4502be8d"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the gradio library using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee239c8d"
      },
      "source": [
        "%pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d798c17"
      },
      "source": [
        "## Create a function to analyze the video\n",
        "\n",
        "### Subtask:\n",
        "Define a Python function that takes the video path as input and uses the Gemini model to analyze it based on the system prompt and safety settings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b52fe89"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the function to analyze the video using the Gemini model, including uploading, waiting, generating content, and deleting the file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3de5389"
      },
      "source": [
        "import time\n",
        "from google.genai import types\n",
        "\n",
        "def analyze_video_with_gemini(video_path):\n",
        "    \"\"\"Analyzes a video using the Gemini model.\n",
        "\n",
        "    Args:\n",
        "        video_path: The path to the video file.\n",
        "\n",
        "    Returns:\n",
        "        The text response from the Gemini model.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the video file upload fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Upload video\n",
        "        video_file = client.files.upload(file=video_path)\n",
        "\n",
        "        # Wait until the uploaded video is available\n",
        "        while video_file.state.name == \"PROCESSING\":\n",
        "            print('.', end='')\n",
        "            time.sleep(5)\n",
        "            video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "        if video_file.state.name == \"FAILED\":\n",
        "            raise ValueError(f\"Video upload failed with state: {video_file.state.name}\")\n",
        "\n",
        "        # Generate content\n",
        "        response = client.models.generate_content(\n",
        "            model=f\"models/{MODEL_ID}\",\n",
        "            contents=[\n",
        "                \"what is the video about\",\n",
        "                video_file\n",
        "            ],\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=system_prompt,\n",
        "                safety_settings=safety_settings,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # Delete video\n",
        "        client.files.delete(name=video_file.name)\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other potential errors\n",
        "        return f\"An error occurred: {e}\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d590ec1a"
      },
      "source": [
        "## Create a gradio interface\n",
        "\n",
        "### Subtask:\n",
        "Use the Gradio library to create a user interface that allows users to upload a video and displays the analysis result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ff0080"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the gradio library and create a Gradio interface to allow users to upload a video and display the analysis result using the previously defined analyze_video_with_gemini function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24aded4c"
      },
      "source": [
        "from logging import debug\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_video_with_gemini,\n",
        "    inputs=gr.Video(),\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"Historic Event Recognition using Gemini\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bd33c7c"
      },
      "source": [
        "## Launch the gradio application\n",
        "\n",
        "### Subtask:\n",
        "Run the Gradio application to make it accessible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1082493"
      },
      "source": [
        "**Reasoning**:\n",
        "Launch the Gradio interface to make it accessible for user interaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c59515f"
      },
      "source": [
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd90e6e0"
      },
      "source": [
        "## Create a function to analyze the video\n",
        "\n",
        "### Subtask:\n",
        "Define a Python function that takes the video path as input and uses the Gemini model to analyze it based on the system prompt and safety settings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e54c2a0"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the function to analyze the video using the Gemini model, including uploading, waiting, generating content, and deleting the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdb868e0"
      },
      "source": [
        "import time\n",
        "from google.genai import types\n",
        "\n",
        "def analyze_video_with_gemini(video_path):\n",
        "    \"\"\"Analyzes a video using the Gemini model.\n",
        "\n",
        "    Args:\n",
        "        video_path: The path to the video file.\n",
        "\n",
        "    Returns:\n",
        "        The text response from the Gemini model.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the video file upload fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Upload video\n",
        "        video_file = client.files.upload(file=video_path)\n",
        "\n",
        "        # Wait until the uploaded video is available\n",
        "        while video_file.state.name == \"PROCESSING\":\n",
        "            print('.', end='')\n",
        "            time.sleep(5)\n",
        "            video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "        if video_file.state.name == \"FAILED\":\n",
        "            raise ValueError(f\"Video upload failed with state: {video_file.state.name}\")\n",
        "\n",
        "        # Generate content\n",
        "        response = client.models.generate_content(\n",
        "            model=f\"models/{MODEL_ID}\",\n",
        "            contents=[\n",
        "                \"what is the video about\",\n",
        "                video_file\n",
        "            ],\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=system_prompt,\n",
        "                safety_settings=safety_settings,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # Delete video\n",
        "        client.files.delete(name=video_file.name)\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other potential errors\n",
        "        return f\"An error occurred: {e}\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84963a5e"
      },
      "source": [
        "## Create a gradio interface\n",
        "\n",
        "### Subtask:\n",
        "Use the Gradio library to create a user interface that allows users to upload a video and displays the analysis result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdda13e0"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the gradio library and create a Gradio interface to allow users to upload a video and display the analysis result using the previously defined analyze_video_with_gemini function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "cc24aad5",
        "outputId": "dd84f2a8-159d-442a-c93c-587d2970ba5c"
      },
      "source": [
        "from logging import debug\n",
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_video_with_gemini,\n",
        "    inputs=gr.Video(),\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"Historic Event Recognition using Gemini\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://89391390f6503d791d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://89391390f6503d791d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POCj-tR2aDsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Analyze_a_Video_Historic_Event_Recognition.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}